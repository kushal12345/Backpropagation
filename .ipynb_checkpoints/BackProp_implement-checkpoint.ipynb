{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          gre       gpa  rank_1  rank_2  rank_3  rank_4\n",
      "209 -0.066657  0.289305       0       1       0       0\n",
      "280  0.625884  1.445476       0       1       0       0\n",
      "33   1.837832  1.603135       0       0       1       0\n",
      "210  1.318426 -0.131120       0       0       0       1\n",
      "93  -0.066657 -1.208461       0       1       0       0\n",
      "84  -0.759199  0.552071       0       0       1       0\n",
      "329 -0.759199 -1.208461       0       0       0       1\n",
      "94   0.625884  0.131646       0       1       0       0\n",
      "266 -0.239793 -0.393886       0       0       0       1\n",
      "126  0.106478  0.394412       1       0       0       0\n",
      "9    0.972155  1.392922       0       1       0       0\n",
      "361 -0.412928  0.263029       1       0       0       0\n",
      "56  -0.239793 -0.525269       0       0       1       0\n",
      "72  -0.932334  0.000263       0       0       0       1\n",
      "132 -0.066657  0.026539       0       1       0       0\n",
      "42   0.106478 -0.630376       0       1       0       0\n",
      "278  0.799020 -1.024525       0       0       0       1\n",
      "376  0.279614  0.630901       0       1       0       0\n",
      "231  0.106478 -0.288780       0       0       1       0\n",
      "385 -1.451740 -0.971971       1       0       0       0\n",
      "77   1.837832  1.603135       0       0       1       0\n",
      "15  -0.932334  0.131646       0       0       1       0\n",
      "391  0.625884  1.287816       0       1       0       0\n",
      "271 -0.412928 -0.157397       0       0       1       0\n",
      "0   -1.798011  0.578348       0       0       1       0\n",
      "396 -0.239793 -0.919418       0       0       1       0\n",
      "114  1.145291  1.182710       0       0       1       0\n",
      "225  1.145291  0.289305       0       0       1       0\n",
      "262 -0.586063 -0.525269       0       0       1       0\n",
      "104  0.625884  1.471752       0       1       0       0\n",
      "..        ...       ...     ...     ...     ...     ...\n",
      "43  -0.759199 -0.209950       0       0       1       0\n",
      "217 -1.105469  0.657178       1       0       0       0\n",
      "190  0.452749 -1.182184       0       1       0       0\n",
      "309 -1.278605 -1.077078       0       0       1       0\n",
      "259  0.452749  1.103880       0       1       0       0\n",
      "105  1.318426 -1.103354       0       1       0       0\n",
      "53   0.799020 -0.315056       0       1       0       0\n",
      "1    0.625884  0.736008       0       0       1       0\n",
      "49  -1.624876 -0.104844       0       0       1       0\n",
      "80   0.972155 -1.287291       0       0       0       1\n",
      "205  1.664697  1.077603       0       0       1       0\n",
      "34  -1.971146 -0.656652       1       0       0       0\n",
      "263  0.279614  1.471752       0       0       1       0\n",
      "91   1.145291  0.657178       1       0       0       0\n",
      "339  0.625884  0.210476       0       0       1       0\n",
      "52   1.318426 -0.052290       0       0       0       1\n",
      "345 -0.759199 -0.945695       0       0       1       0\n",
      "264 -0.586063  1.340369       0       0       1       0\n",
      "241 -0.586063  1.103880       1       0       0       0\n",
      "13   0.972155 -0.814312       0       1       0       0\n",
      "315 -2.490553 -1.444950       0       1       0       0\n",
      "88   0.972155 -0.288780       1       0       0       0\n",
      "273  0.625884 -0.183673       1       0       0       0\n",
      "166 -1.278605 -0.393886       0       0       0       1\n",
      "328 -0.066657 -0.131120       0       1       0       0\n",
      "393  0.279614  0.946220       0       1       0       0\n",
      "134 -0.239793 -1.155908       0       1       0       0\n",
      "306 -0.412928 -0.577822       1       0       0       0\n",
      "383  0.625884  1.603135       1       0       0       0\n",
      "319 -0.412928 -0.288780       1       0       0       0\n",
      "\n",
      "[360 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from preprocess_Data import features, targets, features_test, targets_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"Calculate sigmoid\"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(a):\n",
    "    return a*(1-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 3  # number of hidden units\n",
    "epochs = 5\n",
    "learning_rate = 0.89\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples, n_features = features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_loss = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights\n",
    "weights_input_hidden = np.random.normal(scale=1 / n_features ** -.5, size=(n_features, n_hidden)) # TODO: Replace val1, and val2 with appropriate values, try not to hardcode values, refer to np.random.normal documentation for help\n",
    "weights_hidden_output = np.random.normal(scale=1 / n_features ** -.5, size=n_hidden) # TODO: Replace val3 with appropriate values, try not to hardcode values and instead find a generic way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.24326565804808203\n",
      "Train loss:  0.2783333185213588   WARNING - Loss Increasing\n",
      "Train loss:  0.2681244447783773\n",
      "Train loss:  0.24185490536955087\n",
      "Train loss:  0.2406472608599309\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    del_w_input_hidden = np.zeros(weights_input_hidden.shape)\n",
    "    del_w_hidden_output = np.zeros(weights_hidden_output.shape)# TODO: Something very similar to the expression above, fill in yourself\n",
    "\n",
    "    for x, y in zip(features.values, targets):\n",
    "        # forward pass\n",
    "        # calculate the output\n",
    "        hidden_input = np.dot(x, weights_input_hidden)\n",
    "        hidden_activations = sigmoid(hidden_input)\n",
    "\n",
    "\n",
    "        output_layer_input = np.dot(hidden_activations, weights_hidden_output) \n",
    "        output = sigmoid(output_layer_input)\n",
    "        \n",
    "        # calculate the error\n",
    "        error = y - output\n",
    "        \n",
    "        # backward pass\n",
    "        del_err_output=error * derivative(output)\n",
    "        error_first_layer=np.dot(del_err_output, weights_hidden_output)\n",
    "        del_err_input=error_first_layer * derivative(hidden_activations)\n",
    "             \n",
    "\n",
    "        # calculate error gradient in output unit\n",
    "        output_error = error * output * (1 - output)\n",
    "\n",
    "        # propagate errors to hidden layer\n",
    "        hidden_error = error * hidden_activations * (1 - hidden_activations)# TODO: Fill this, similar to output_error above. For help look at backpropogation.py script from last time\n",
    "\n",
    "        # update the change in weights\n",
    "        del_w_hidden_output += output_error * hidden_activations\n",
    "        del_w_input_hidden +=  del_err_input * x[:, None]# TODO: Fill this yourself. For help look at backpropogation.py script from last time\n",
    "    \n",
    "    # update weights\n",
    "    weights_hidden_output += learning_rate * del_w_hidden_output / n_examples\n",
    "    weights_input_hidden += del_w_input_hidden * learning_rate# TODO: Fill this yourself. For help look at backpropogation.py script from last time\n",
    "\n",
    "    if e % (epochs / 10) == 0:\n",
    "        hidden_activations = sigmoid(np.dot(x, weights_input_hidden))\n",
    "        out = sigmoid(np.dot(hidden_activations,\n",
    "                             weights_hidden_output))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27390377 0.61010527 0.28826182 0.22220029 0.18471822 0.2885956\n",
      " 0.30582137 0.39731097 0.27852342 0.30054933 0.70715057 0.13812542\n",
      " 0.21063782 0.69205914 0.23693945 0.1648654  0.24192952 0.29386345\n",
      " 0.1050004  0.12385708 0.16739599 0.13588354 0.46361794 0.15713201\n",
      " 0.24073234 0.61116318 0.25019708 0.67084864 0.27856796 0.70960847\n",
      " 0.12871729 0.29798123 0.27865236 0.12986536 0.27147773 0.23532944\n",
      " 0.221709   0.15376037 0.16103394 0.25443652]\n"
     ]
    }
   ],
   "source": [
    "hidden = sigmoid(np.dot(features_test, weights_input_hidden))\n",
    "out = sigmoid(np.dot(hidden, weights_hidden_output))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 0.800\n"
     ]
    }
   ],
   "source": [
    "predictions = out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
