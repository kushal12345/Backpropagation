{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          gre       gpa  rank_1  rank_2  rank_3  rank_4\n",
      "209 -0.066657  0.289305       0       1       0       0\n",
      "280  0.625884  1.445476       0       1       0       0\n",
      "33   1.837832  1.603135       0       0       1       0\n",
      "210  1.318426 -0.131120       0       0       0       1\n",
      "93  -0.066657 -1.208461       0       1       0       0\n",
      "84  -0.759199  0.552071       0       0       1       0\n",
      "329 -0.759199 -1.208461       0       0       0       1\n",
      "94   0.625884  0.131646       0       1       0       0\n",
      "266 -0.239793 -0.393886       0       0       0       1\n",
      "126  0.106478  0.394412       1       0       0       0\n",
      "9    0.972155  1.392922       0       1       0       0\n",
      "361 -0.412928  0.263029       1       0       0       0\n",
      "56  -0.239793 -0.525269       0       0       1       0\n",
      "72  -0.932334  0.000263       0       0       0       1\n",
      "132 -0.066657  0.026539       0       1       0       0\n",
      "42   0.106478 -0.630376       0       1       0       0\n",
      "278  0.799020 -1.024525       0       0       0       1\n",
      "376  0.279614  0.630901       0       1       0       0\n",
      "231  0.106478 -0.288780       0       0       1       0\n",
      "385 -1.451740 -0.971971       1       0       0       0\n",
      "77   1.837832  1.603135       0       0       1       0\n",
      "15  -0.932334  0.131646       0       0       1       0\n",
      "391  0.625884  1.287816       0       1       0       0\n",
      "271 -0.412928 -0.157397       0       0       1       0\n",
      "0   -1.798011  0.578348       0       0       1       0\n",
      "396 -0.239793 -0.919418       0       0       1       0\n",
      "114  1.145291  1.182710       0       0       1       0\n",
      "225  1.145291  0.289305       0       0       1       0\n",
      "262 -0.586063 -0.525269       0       0       1       0\n",
      "104  0.625884  1.471752       0       1       0       0\n",
      "..        ...       ...     ...     ...     ...     ...\n",
      "43  -0.759199 -0.209950       0       0       1       0\n",
      "217 -1.105469  0.657178       1       0       0       0\n",
      "190  0.452749 -1.182184       0       1       0       0\n",
      "309 -1.278605 -1.077078       0       0       1       0\n",
      "259  0.452749  1.103880       0       1       0       0\n",
      "105  1.318426 -1.103354       0       1       0       0\n",
      "53   0.799020 -0.315056       0       1       0       0\n",
      "1    0.625884  0.736008       0       0       1       0\n",
      "49  -1.624876 -0.104844       0       0       1       0\n",
      "80   0.972155 -1.287291       0       0       0       1\n",
      "205  1.664697  1.077603       0       0       1       0\n",
      "34  -1.971146 -0.656652       1       0       0       0\n",
      "263  0.279614  1.471752       0       0       1       0\n",
      "91   1.145291  0.657178       1       0       0       0\n",
      "339  0.625884  0.210476       0       0       1       0\n",
      "52   1.318426 -0.052290       0       0       0       1\n",
      "345 -0.759199 -0.945695       0       0       1       0\n",
      "264 -0.586063  1.340369       0       0       1       0\n",
      "241 -0.586063  1.103880       1       0       0       0\n",
      "13   0.972155 -0.814312       0       1       0       0\n",
      "315 -2.490553 -1.444950       0       1       0       0\n",
      "88   0.972155 -0.288780       1       0       0       0\n",
      "273  0.625884 -0.183673       1       0       0       0\n",
      "166 -1.278605 -0.393886       0       0       0       1\n",
      "328 -0.066657 -0.131120       0       1       0       0\n",
      "393  0.279614  0.946220       0       1       0       0\n",
      "134 -0.239793 -1.155908       0       1       0       0\n",
      "306 -0.412928 -0.577822       1       0       0       0\n",
      "383  0.625884  1.603135       1       0       0       0\n",
      "319 -0.412928 -0.288780       1       0       0       0\n",
      "\n",
      "[360 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from preprocess_Data import features, targets, features_test, targets_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"Calculate sigmoid\"\"\"\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(a):\n",
    "    return a*(1-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 3  # number of hidden units\n",
    "epochs = 1000\n",
    "learning_rate = 0.812"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples, n_features = features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_loss = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights\n",
    "weights_input_hidden = np.random.normal(scale=1 / n_features ** -.5, size=(n_features, n_hidden)) # TODO: Replace val1, and val2 with appropriate values, try not to hardcode values, refer to np.random.normal documentation for help\n",
    "weights_hidden_output = np.random.normal(scale=1 / n_features ** -.5, size=n_hidden) # TODO: Replace val3 with appropriate values, try not to hardcode values and instead find a generic way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.2671463930865848\n",
      "Train loss:  0.1989759115397518\n",
      "Train loss:  0.19940521415795828   WARNING - Loss Increasing\n",
      "Train loss:  0.19980247793162495   WARNING - Loss Increasing\n",
      "Train loss:  0.19993483137948964   WARNING - Loss Increasing\n",
      "Train loss:  0.19828037093634765\n",
      "Train loss:  0.19356443153468356\n",
      "Train loss:  0.1925593212238347\n",
      "Train loss:  0.19225911651001304\n",
      "Train loss:  0.19204568409593922\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    del_w_input_hidden = np.zeros(weights_input_hidden.shape)\n",
    "    del_w_hidden_output = np.zeros(weights_hidden_output.shape)# TODO: Something very similar to the expression above, fill in yourself\n",
    "\n",
    "\n",
    "    hidden_input = np.dot(features.values, weights_input_hidden)\n",
    "    hidden_activations = sigmoid(hidden_input)\n",
    "\n",
    "\n",
    "    output_layer_input = np.dot(hidden_activations, weights_hidden_output) \n",
    "    output = sigmoid(output_layer_input)\n",
    "        \n",
    "        # calculate the error\n",
    "    error = targets - output\n",
    "        \n",
    "\n",
    "        # calculate error gradient in output unit\n",
    "    output_error = np.multiply(error , output,(1-output)).reshape(-1,1)\n",
    "    tmp = np.dot(output_error,weights_hidden_output.reshape(-1,1).T)\n",
    "    sig_prod = np.multiply(hidden_activations, derivative(hidden_activations))\n",
    "    \n",
    "    hidden_error = np.multiply(tmp,sig_prod)\n",
    "    \n",
    "\n",
    "        # propagate errors to hidden layer\n",
    "       # hidden_error = error * hidden_activations * (1 - hidden_activations)# TODO: Fill this, similar to output_error above. For help look at backpropogation.py script from last time\n",
    "\n",
    "        # update the change in weights\n",
    "    del_w_hidden_output = np.mean(np.multiply(output_error, hidden_activations),axis=0)\n",
    "    del_w_input_hidden =  np.dot(hidden_error.T , features.values).T# TODO: Fill this yourself. For help look at backpropogation.py script from last time\n",
    "    \n",
    "    # update weights\n",
    "    weights_hidden_output += learning_rate * del_w_hidden_output / n_examples\n",
    "    weights_input_hidden += del_w_input_hidden * learning_rate# TODO: Fill this yourself. For help look at backpropogation.py script from last time\n",
    "\n",
    "    if e % (epochs / 10) == 0:\n",
    "        hidden_activations = sigmoid(np.dot(features.values, weights_input_hidden))\n",
    "        out = sigmoid(np.dot(hidden_activations,\n",
    "                             weights_hidden_output))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18667487 0.39932414 0.07915841 0.32199864 0.28095884 0.29723758\n",
      " 0.07019386 0.36906491 0.15548891 0.10307205 0.71873967 0.24170213\n",
      " 0.35314034 0.18798621 0.27131949 0.34159499 0.27851484 0.15647215\n",
      " 0.31076952 0.31876424 0.31648296 0.35880726 0.37484448 0.34340439\n",
      " 0.35707896 0.45342937 0.33816475 0.4294794  0.22408857 0.72763034\n",
      " 0.31499744 0.17477934 0.40737699 0.32690362 0.2127183  0.26937311\n",
      " 0.36846707 0.22589358 0.22789554 0.30913124]\n"
     ]
    }
   ],
   "source": [
    "hidden = sigmoid(np.dot(features_test, weights_input_hidden))\n",
    "out = sigmoid(np.dot(hidden, weights_hidden_output))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 0.750\n"
     ]
    }
   ],
   "source": [
    "predictions = out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
